# âš•ï¸Blood Pressure and AVC Risk MonitoringðŸ©ºðŸ«€

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du **Master USPN (Big Data)**. Il s'agit d'un Ã©cosystÃ¨me complet de traitement de donnÃ©es de santÃ© en temps rÃ©el utilisant une architecture distribuÃ©e pour prÃ©dire les risques d'AVC (Accident Vasculaire CÃ©rÃ©bral).
---

## ðŸš€ DÃ©ploiement (Installation & Run)

Suivez ces Ã©tapes pour installer l'environnement et lancer le pipeline de prÃ©diction sur votre machine locale.

## 1. PrÃ©requis
* **Docker Desktop** : Assurez-vous qu'il est installÃ© et que le moteur WSL2 est activÃ© (pour Windows).
* **Python 3.10+** : VÃ©rifiez votre version avec `python --version`.
* **Git** : Pour cloner le rÃ©pertoire.
* **ClÃ© API**

## 2. RÃ©cupÃ©ration du Projet
Ouvrez un terminal (PowerShell ou Bash) et exÃ©cutez :
```bash
git clone https://github.com/Ange-Paul-Emmanuel/blood_pressure_obersavability_docker_project/tree/master
cd "PROJET BLOOD PRESSURE" 
```
## 3. Lancement de l'Infrastructure (Docker)
DÃ©marrez tous les services (Zookeeper, Kafka, Elasticsearch, Kibana, Kafka-UI) en arriÃ¨re-plan

```bash
docker-compose up -d
```
Exemple de sortie du terminal
```bash
[+] Running 5/5
 âœ” Container zookeeper      Started                                     3.7s 
 âœ” Container elasticsearch  Started                                     3.7s 
 âœ” Container kibana         Started                                     2.3s 
 âœ” Container kafka          Started                                     2.2s 
 âœ” Container kafka-ui       Started                                     2.0s
```
- VÃ©rification : Attendez environ 30 secondes, puis tapez docker ``` docker-compose ps ``` pour vÃ©rifier que tous les containers affichent le statut Up

Exemple de sortie du terminal

```bash
NAME            IMAGE                                                  COMMAND                  SERVICE         CREATED       STATUS          PORTS
elasticsearch   docker.elastic.co/elasticsearch/elasticsearch:8.10.2   "/bin/tini -- /usr/lâ€¦"   elasticsearch   6 days ago    Up 10 minutes   0.0.0.0:9200->9200/tcp, [::]:9200->9200/tcp
kafka           confluentinc/cp-kafka:6.2.0                            "/etc/confluent/dockâ€¦"   kafka           6 days ago    Up 8 minutes    0.0.0.0:9092->9092/tcp, [::]:9092->9092/tcp
kafka-ui        provectuslabs/kafka-ui:latest                          "/bin/sh -c 'java --â€¦"   kafka-ui        6 days ago    Up 10 minutes   0.0.0.0:8080->8080/tcp, [::]:8080->8080/tcp
kibana          docker.elastic.co/kibana/kibana:8.10.2                 "/bin/tini -- /usr/lâ€¦"   kibana          6 days ago    Up 10 minutes   0.0.0.0:5601->5601/tcp, [::]:5601->5601/tcp
zookeeper       confluentinc/cp-zookeeper:6.2.0                        "/etc/confluent/dockâ€¦"   zookeeper       6 days ago    Up 10 minutes   2181/tcp, 2888/tcp, 3888/tcp
```

## 4. Configuration de l'environnement Python
```bash
# CrÃ©ation de l'environnement
python -m venv venv

# Activation (Windows)
.\venv\Scripts\activate

# Activation (Mac/Linux)
# source venv/bin/activate

# Installation des bibliothÃ¨ques nÃ©cessaires
pip install -r requirements.txt
```
## 5. ðŸ”‘ Configuration et accÃ¨s au LLM

Le projet utilise l'agent ```MedicalAgent``` de ```medical_agent.py``` qui s'appuie sur le LLM OpenSource ```llama-3.1-8b-instant``` ultra-rapides de Groq pour analyser les risques mÃ©dicaux. 
Pour que l'analyse fonctionne, tu dois possÃ©der une clÃ© API valide.

Obtenir une clÃ© API gratuite :
- Rendez-vous sur le Groq Cloud Console : https://console.groq.com/.
- Connectez-vous avec votre compte Google ou GitHub.
- Dans le menu latÃ©ral gauche, cliquez sur "API Keys".
- Cliquez sur le bouton "Create API Key".
- Donnez-lui un nom (ex: Blood_pressure_Project_IA) et copiez la clÃ© gÃ©nÃ©rÃ©e.

Configurer la variable d'environnement :
Pour que le script ```medical_agent.py``` puisse lire la clÃ© via ```os.getenv('GROQ_API_KEY')```, tu dois l'ajouter Ã  ton fichier .env.

- Ã€ la racine du projet crÃ©e le fichier nommÃ© .env.
- Ajoute la ligne suivante Ã  l'intÃ©rieur : ```GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx```

## 6. ExÃ©cution du Pipeline (Ordre de lancement)

Pour que le flux de donnÃ©es soit correctement traitÃ©, ouvrez quatre terminaux diffÃ©rents et lancez les scripts dans l'ordre suivant :
```bash
# ExcÃ©cute le Simulateur de donnÃ©es mÃ©dicales
generator.py

# DÃ©marre l'envoi des donnÃ©es patients simulÃ©es vers Kafka.
python producer.py

# Lance l'IA qui Ã©coute Kafka et prÃ©dit les risques d'AVC.
python medical_agent.py

# PrÃ©pare la rÃ©ception et l'indexation dans Elasticsearch.
python consummer.py
```
## 7. AccÃ¨s aux Interfaces Graphiques : 

  ### Kafka UI
Une fois le pipeline en marche, vous pouvez surveiller le systÃ¨me via :
Kafka UI : http://localhost:8080 (pour voir les messages dans les topics).

- Cliquer sur ```Topics``` dans le menu de gauche.

- Puis Cliquer sur ```fhir-observations``` 

- Aller dans l'onglet ```Messages```

### ELASTIC : Kibana
Kibana : http://localhost:5601 (pour visualiser les dashboards et les alertes).

- Allez dans ```Management``` > ```Stack Management```

- Puis Cliquer sur ```Data Views``` sous la section *Kibana*

- Cliquez sur ```Create data view```

- Dans le champ *Name*, saisissez ```patients-alerts``` puis ```patients-alerts-*``` dans *Index pattern*

### Comment accÃ©der au Dashboard prÃ©-configurÃ©

Une fois que les services sont lancÃ©s et que les donnÃ©es circulent, vous n'avez pas besoin de recrÃ©er les graphiques. Voici comment ouvrir le tableau de bord existant :

AccÃ¨s direct via l'interface
1. Ouvrez votre navigateur sur [http://localhost:5601](http://localhost:5601).
2. Dans le menu latÃ©ral gauche, cliquez sur l'icÃ´ne **Dashboard** (ou tapez "Dashboard" dans la barre de recherche en haut).
3. Dans la liste qui s'affiche, recherchez et cliquez sur le nom de votre dashboard ( `Patient Monitoring`).
4. AperÃ§u de tableau de bord
   
<img width="1260" height="804" alt="Capture dâ€™Ã©cran 2026-01-29 184556" src="https://github.com/user-attachments/assets/147f20a4-8898-4e23-b46e-b2f9bb181932" />

<img width="1260" height="491" alt="Capture dâ€™Ã©cran 2026-01-29 184803" src="https://github.com/user-attachments/assets/d13c3433-5335-4657-8db2-6b10a7285063" />

---

## ðŸ“‚ Arborescence du Projet (Project Tree)

```text
PROJET BLOOD PRESSURE/
â”œâ”€â”€ outputs_bp/                 # Artefacts et modÃ¨les exportÃ©s
â”‚   â”œâ”€â”€ dataset_enrichi.csv        # Dataset aprÃ¨s feature engineering
â”‚   â””â”€â”€ my_random_forest_avc.joblib # ModÃ¨le Random Forest entraÃ®nÃ©
â”œâ”€â”€ venv/                       # Environnement virtuel Python
â”œâ”€â”€ .env                        # Configuration des accÃ¨s (Clef API)
â”œâ”€â”€ .gitignore                  # Fichiers Ã  exclure du versioning
â”œâ”€â”€ docker-compose.yml          # Orchestration des conteneurs Docker(Kafka, Zookeeper, ES, Kibana)
â”œâ”€â”€ producer.py                 # Ingestion des donnÃ©es patients (Source)
â”œâ”€â”€ medical_agent.py            # Agent IA (PrÃ©diction AVC en temps rÃ©el)
â”œâ”€â”€ consumer.py                 # Indexation finale dans Elasticsearch
â”œâ”€â”€ generator.py                # Simulateur de donnÃ©es mÃ©dicales
â”œâ”€â”€ reset_topic.py              # Script utilitaire de purge Kafka
â”œâ”€â”€ requirements.txt            # DÃ©pendances du projet
â”œâ”€â”€ ML_Model.ipynb              # Notebook d'entraÃ®nement et modÃ¨le de prÃ©diction
â””â”€â”€ patients_sains.json         # Stock localement les donnÃ©es des patients sains
